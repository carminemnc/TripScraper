{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vcaminic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import re\n",
    "from utils import *\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "# import these modules\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from LeXmo import LeXmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('tripadvisor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vcaminic\\Desktop\\00_CODE\\Studies\\ScripAdvisor\\utils.py:128: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  emo_df = data['review_body'].apply(lambda x: LeXmo.LeXmo(x)).apply(pd.Series).drop(\n"
     ]
    }
   ],
   "source": [
    "data, emojis, tokens_df, bigr_with_sw, trigr_with_sw, tokens, corpus, words = dfCleaner(\n",
    "    data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vcaminic\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:454: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load Aspect-Based Sentiment Analysis model\n",
    "absa_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"yangheng/deberta-v3-base-absa-v1.1\")\n",
    "absa_model = AutoModelForSequenceClassification \\\n",
    "    .from_pretrained(\"yangheng/deberta-v3-base-absa-v1.1\")\n",
    "\n",
    "# Load a traditional Sentiment Analysis model\n",
    "sentiment_model_path = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "sentiment_model = pipeline(\"sentiment-analysis\", model=sentiment_model_path,\n",
    "                           tokenizer=sentiment_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: food is bad\n",
      "\n",
      "Sentiment of aspect 'food' is:\n",
      "Label negative: 0.9921167492866516\n",
      "Label neutral: 0.0059877787716686726\n",
      "Label positive: 0.0018954770639538765\n",
      "\n",
      "Overall sentiment: negative with score 0.9428786039352417\n"
     ]
    }
   ],
   "source": [
    "sentence = 'food is bad'\n",
    "print(f\"Sentence: {sentence}\")\n",
    "print()\n",
    "\n",
    "# ABSA of \"food\"\n",
    "aspect = \"food\"\n",
    "inputs = absa_tokenizer(\n",
    "    f\"[CLS] {sentence} [SEP] {aspect} [SEP]\", return_tensors=\"pt\")\n",
    "outputs = absa_model(**inputs)\n",
    "probs = F.softmax(outputs.logits, dim=1)\n",
    "probs = probs.detach().numpy()[0]\n",
    "print(f\"Sentiment of aspect '{aspect}' is:\")\n",
    "for prob, label in zip(probs, [\"negative\", \"neutral\", \"positive\"]):\n",
    "    print(f\"Label {label}: {prob}\")\n",
    "print()\n",
    "# Sentiment of aspect 'food' is:\n",
    "# Label negative: 0.0009989114478230476\n",
    "# Label neutral: 0.001823813421651721\n",
    "# Label positive: 0.997177243232727\n",
    "\n",
    "# # ABSA of \"service\"\n",
    "# aspect = \"service\"\n",
    "# inputs = absa_tokenizer(\n",
    "#     f\"[CLS] {sentence} [SEP] {aspect} [SEP]\", return_tensors=\"pt\")\n",
    "# outputs = absa_model(**inputs)\n",
    "# probs = F.softmax(outputs.logits, dim=1)\n",
    "# probs = probs.detach().numpy()[0]\n",
    "# print(f\"Sentiment of aspect '{aspect}' is:\")\n",
    "# for prob, label in zip(probs, [\"negative\", \"neutral\", \"positive\"]):\n",
    "#     print(f\"Label {label}: {prob}\")\n",
    "# print()\n",
    "# Sentiment of aspect 'service' is:\n",
    "# Label negative: 0.9946129322052002\n",
    "# Label neutral: 0.002369985682889819\n",
    "# Label positive: 0.003017079783603549\n",
    "\n",
    "# Overall sentiment of the sentence\n",
    "sentiment = sentiment_model([sentence])[0]\n",
    "print(\n",
    "    f\"Overall sentiment: {sentiment['label']} with score {sentiment['score']}\")\n",
    "# Overall sentiment: Negative with score 0.7706006765365601"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n"
     ]
    }
   ],
   "source": [
    "sentence = 'mi fai completamente schifo'\n",
    "\n",
    "print(sentiment_model([sentence])[0]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absa_predictor(sentence, word):\n",
    "\n",
    "    sentence = sentence\n",
    "    aspect = word\n",
    "    inputs = absa_tokenizer(\n",
    "        f\"[CLS] {sentence} [SEP] {aspect} [SEP]\", return_tensors=\"pt\")\n",
    "    outputs = absa_model(**inputs)\n",
    "    probs = F.softmax(outputs.logits, dim=1)\n",
    "    probs = probs.detach().numpy()[0]\n",
    "    labels = dict(zip([\"negative\", \"neutral\", \"positive\"], probs))\n",
    "    result = max(labels, key=labels.get)\n",
    "    # print(sentence)\n",
    "    print(\n",
    "        f'Sentiment for {aspect} is {result} with a prob of: {max(labels.values())}')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment for position is positive with a prob of: 0.9670966267585754\n",
      "Sentiment for room is neutral with a prob of: 0.5143488645553589\n"
     ]
    }
   ],
   "source": [
    "absa_predictor('Perfectly located for accessing the old town and wandering its narrow streets. \\\n",
    "    Sunday has a small flea market which is worth a browse when enjoying an expresso. \\\n",
    "        Hotel is average, room ok, we had an attic room which had noises from the pigeons on the roof.',\n",
    "               'position')\n",
    "\n",
    "absa_predictor('Perfectly located for accessing the old town and wandering its narrow streets. \\\n",
    "    Sunday has a small flea market which is worth a browse when enjoying an expresso. \\\n",
    "        Hotel is average, room ok, we had an attic room which had noises from the pigeons on the roof.',\n",
    "               'room')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9891127"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(result.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'negative': 0.9891127, 'neutral': 0.004781139, 'positive': 0.006106108}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'we did a corporate event with 125 pax at the royal plaza delhi on 24th june 23 and are 100 satisfied with the quality of services banquet manager was extremely helpful and even handled some last minute requirements from our side food and hospitality was up to the mark really recommend the royal plaza delhi to all '"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[4, 'review_body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "sentence = 'questo telefpmp fa schifo, ma il servizio Ã¨ veramente ottimo'\n",
    "\n",
    "print(absa_predictor(sentence, 'telefono'))\n",
    "\n",
    "\n",
    "print(sentiment_model([sentence])[0]['label'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
